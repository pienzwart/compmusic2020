---
title:  'Computational Musicology'
author: 'Pien Zwart'
date:   'February--March 2020'
output: 
    flexdashboard::flex_dashboard:
        storyboard: true
        theme: readable
        highlight: monochrome
        
        
        
        
---

```{r setup}
# In order to use these packages, we need to install flexdashboard, plotly, and Cairo.
library(tidyverse)
library(plotly)
library(spotifyr)
source('spotify.R')
library(compmus)
```

### The Timbre and Chroma in Apocalypse by Cigarettes After Sex and Highest In The Room by Travis Scott.

```{r}

apocalypse_timbre <- get_tidy_audio_analysis('0yc6Gst2xkRu0eMLeRMGCX') %>% 
    compmus_align(bars, segments) %>% 
    select(bars) %>% unnest(bars) %>% 
    mutate(
        pitches = 
            map(segments, 
                compmus_summarise, pitches, 
                method = 'rms', norm = 'euclidean')) %>% 
    mutate(
        timbre = 
            map(segments, 
                compmus_summarise, timbre, 
                method = 'mean'))



apocalypse_timbre %>% 
    compmus_self_similarity(timbre, 'cosine') %>% 
    ggplot(
        aes(
            x = xstart + xduration / 2, 
            width = xduration,
            y = ystart + yduration / 2,
            height = yduration,
            fill = d)) + 
    geom_tile() +
    coord_fixed() +
    scale_fill_viridis_c(option = 'E', guide = 'none') +
    theme_classic() +
    labs(x = '', y = '', title = 'Apocalypse', subtitle = 'Timbre')



highest_timbre <- get_tidy_audio_analysis('3eekarcy7kvN4yt5ZFzltW') %>% 
    compmus_align(beats, segments) %>% 
    select(beats) %>% unnest(beats) %>% 
    mutate(
        pitches = 
            map(segments, 
                compmus_summarise, pitches, 
                method = 'rms', norm = 'euclidean')) %>% 
    mutate(
        timbre = 
            map(segments, 
                compmus_summarise, timbre, 
                method = 'mean'))



highest_timbre %>% 
    compmus_self_similarity(timbre, 'cosine') %>% 
    ggplot(
        aes(
            x = xstart + xduration / 2, 
            width = xduration,
            y = ystart + yduration / 2,
            height = yduration,
            fill = d)) + 
    geom_tile() +
    coord_fixed() +
    scale_fill_viridis_c(option = 'E', guide = 'none') +
    theme_classic() +
    labs(x = '', y = '', title = 'Highest In The Room', subtitle = 'Timbre')


apocalypse_chroma <- get_tidy_audio_analysis('0yc6Gst2xkRu0eMLeRMGCX') %>% 
    compmus_align(bars, segments) %>% 
    select(bars) %>% unnest(bars) %>% 
    mutate(
        pitches = 
            map(segments, 
                compmus_summarise, pitches, 
                method = 'mean', norm = 'manhattan')) %>% 
    mutate(
        chroma = 
            map(segments, 
                compmus_summarise, timbre, 
                method = 'mean'))



apocalypse_chroma %>% 
    compmus_self_similarity(chroma, 'manhattan') %>% 
    ggplot(
        aes(
            x = xstart + xduration / 2, 
            width = xduration,
            y = ystart + yduration / 2,
            height = yduration,
            fill = d)) + 
    geom_tile() +
    coord_fixed() +
    scale_fill_viridis_c(option = 'E', guide = 'none') +
    theme_classic() +
    labs(x = '', y = '', title = 'Apocalypse', subtitle = 'Chroma')


highest_chroma <- get_tidy_audio_analysis('3eekarcy7kvN4yt5ZFzltW') %>% 
    compmus_align(bars, segments) %>% 
    select(bars) %>% unnest(bars) %>% 
    mutate(
        pitches = 
            map(segments, 
                compmus_summarise, pitches, 
                method = 'mean', norm = 'manhattan')) %>% 
    mutate(
        chroma = 
            map(segments, 
                compmus_summarise, timbre, 
                method = 'mean'))



highest_chroma %>% 
    compmus_self_similarity(chroma, 'manhattan') %>% 
    ggplot(
        aes(
            x = xstart + xduration / 2, 
            width = xduration,
            y = ystart + yduration / 2,
            height = yduration,
            fill = d)) + 
    geom_tile() +
    coord_fixed() +
    scale_fill_viridis_c(option = 'E', guide = 'none') +
    theme_classic() +
    labs(x = '', y = '', title = 'Highest In The Room', subtitle = 'Chroma')

```

*** 
There are only two songs that appear in both our playlists: Apocalypse by Cigarettes After Sex and Highest In The Room by Travis Scott. These songs are very different in genre. Apocalypse is slow pop and Highest In The Room is hiphop. So it could be interesting to look at the differences in the self-similarity matrixes. I don't really know how I can make it more workable, so that they are for example, standing next to each other. In all the figures I see a very clear line and a recurring pattern. But I don't see a lot of differences in timbre and chroma. I see almost the same things in timbre and chroma in the figures of Apocalypse. And the same things in timbre and chroma in the figures of Highest In The Room. I do see difference in the patterns of the two songs but I don't know exactly what this difference means... In the visualization of Highest In The Room, there is a clear pattern in the beginning but after two thirds of the song, there is a big change. It becomes instrumental till the end of the song. You can see this in the timbre visualization between 100 and 150. In the song Apocalypse, there is more structure in the pattern but also some differences. In the vocal part, there are some little changes but the instrumental part is more like a river, it continues. I think that you can see that in both the visualizations timbre and chroma. 

### Pien versus Pim

For my corpus, I would like to compare my Spotify Wrapped playlist of 2019 to the one of my boyfriend, Pim. Our taste in music is very different and those lists are representing this difference. I think it’s interesting to compare these two playlists. I’m more into soft pop music, singer-/songwriters, also a little classical music, film music, etc. And Pim is more into Drum & Bass, Rap, Hiphop, etc. But we appreciate each others taste of music increasingly since we've been together. For a research question I would think of how different our music tastes really are. At first glance, they are very different. But maybe there are some underlying similarities. And what those differenses and similarities mean.




### Pim is dancing a lot more

```{r}
pien_2019 <- get_playlist_audio_features('spotify', '37i9dQZF1EtqET0jdwPeZm')
pim_2019 <- get_playlist_audio_features('spotify', '37i9dQZF1Etc8rOydKv4e7')

spotify_wrapped_2019 <- pim_2019 %>% mutate(playlist = "Pim") %>%
  bind_rows(pien_2019 %>% mutate(playlist = "Pien"))

dancing <- spotify_wrapped_2019 %>%    # Start with awards.
  mutate(
    mode = ifelse(mode == 0, 'Minor', 'Major')
  ) %>%
  ggplot(aes(x = danceability,
      y = energy,
      size = loudness,
      colour = factor(mode), label = track.name)) +
  geom_point() +               # Scatter plot.
  geom_rug(size = 0.1) +       # Add 'fringes' to show data distribution.
  facet_wrap(~ playlist) +     # Separate charts per playlist.
  scale_x_continuous(          # Fine-tune the x axis.
    limits = c(0, 1),
    breaks = c(0, 0.50, 1),  # Use grid-lines for quadrants only.
    minor_breaks = NULL      # Remove 'minor' grid-lines.
  ) +
  scale_y_continuous(          # Fine-tune the y axis in the same way.
    limits = c(0, 1),
    breaks = c(0, 0.50, 1),
    minor_breaks = NULL
  ) +
  scale_colour_brewer(         # Use the Color Brewer to choose a palette.
    type = "qual",           # Qualitative set.
    palette = "Paired"       # Name of the palette is 'Paired'.
  ) +
  scale_size_continuous(       # Fine-tune the sizes of each point.
    trans = "exp",           # Use an exp transformation to emphasise loud.
    guide = "none"           # Remove the legend for size.
  ) +
  theme_light() +              # Use a simpler them.
  labs(                        # Make the titles nice.
    x = "Danceability",
    y = "Energy",
    colour = "Mode"
  )




ggplotly(dancing)



```


***
I have some first findings, measured by Spotify, that are interesting: 
The music that Pim listens to is more danceable (M = 0.72, SD = 0.13) than the music I listen to (M = 0.48, SD = 0.19). Also there is a difference in energy. Pim’s playlist is way more energetic (M = 0.68, SD = 0.18) than mine (M = 0.34, SD = 0.25). If we look at the loudness category, Pim’s playlist is louder (M = -6.72, SD = 2.41) than mine (M = -14.1, SD = 8.79). In the figure below, we can see the differences that I discussed above. In Pim's figure, almost all of the points/dots are on the top right. This means, that the the energy and danceability is very high. The loudness is indicated with the size of the points/dots. In my figure, the points/dots are more spread out. But almost all the points/dots are very small. So in the size (loudness), Pim is more diverse. And my figure is more stable. Which is a little strange because my standard deviation is a lot bigger than Pim's. To make this more clear, I made a figure of the loudness. 

### To understand the difference in Loudness, I made a nice figure.

```{r fig.width=5, fig.height=8}
loudness <- spotify_wrapped_2019 %>%
  ggplot(aes(x = playlist, y = loudness)) +
  geom_violin()

ggplotly(loudness)
```

***
In the figure we see that Pim is more specific and I am more diverse and stable. This makes more sense. My standard deviation of loudness is large because I listen to more different types of music. A reason for this could be that I have to listen a lot of music for my study, musicology. And this is especially classical music. 

### Our similarities!


This table shows us a summery of all the Spotify features. In the previous tab I discussed the difference in Danceability, Energy and Loudness. If we look at the Acousticness, there is also a quit large difference. 

But there are also similarities like the Keys of our playlists. If we look at the results of Pim in this category, it would mean in the pitch class: F/F#. My results for Key would mean in pitch class: E/F. 

Also the modes are close to each other. In the table we see that Pim en I both listen to major, minor and everything in between.

Apparently, Pim en I are both not really into cheerful music. We score pretty low on Valence, especially I am. But I didn't expect that Pim would be pretty close. 

The results of speechiness seems a little extreme to me. Despite the fact that Pim listens to rap, the results are very low. I would expect that the results of the speechiness in Pim’s playlist would be between 0.33 and 0.66. I don’t think I have to exclude this because it might be an interesting thing to investigate more. 

*** 

| Danceability | Mean |  SD  |
|--------------|------|------|
| Pim          | 0.72 | 0.13 |
| Pien         | 0.48 | 0.19 |

|Energy        | Mean |  SD  |
|--------------|------|------|
| Pim          | 0.68 | 0.18 |
| Pien         | 0.34 | 0.25 |

| Loudness     | Mean |  SD  |
|--------------|------|------|
| Pim          | -6.72| 2.41 |
| Pien         | -14.1| 8.79 |

| Acousticness | Mean |  SD  |
|--------------|------|------|
| Pim          | 0.13 | 0.19 |
| Pien         | 0.63 | 0.36 |

|Key           | Mean |  SD  |
|--------------|------|------|
| Pim          | 5.43 | 3.74 |
| Pien         | 4.54 | 3.35 |

| Mode         | Mean |  SD  |
|--------------|------|------|
| Pim          | 0.53 | 0.50 |
| Pien         | 0.57 | 0.49 |

| Speechiness  | Mean |  SD  |
|--------------|------|------|
| Pim          | 0.14 | 0.11 |
| Pien         | 0.06 | 0.06 |

Valence        | Mean |  SD  |
|--------------|------|------|
| Pim          | 0.40 | 0.24 |
| Pien         | 0.26 | 0.19 |

| Liveness     | Mean |  SD  |
|--------------|------|------|
| Pim          | 0.18 | 0.12 |
| Pien         | 0.16 | 0.14 |

| Tempo        | Mean |  SD  |
|--------------|------|------|
| Pim          | 129  | 30.8 |
| Pien         | 113  | 32.2 |

***





### Apocalypse and Highest In The Room in a chromagram

```{r}
apocalypse <- 
    get_tidy_audio_analysis('0yc6Gst2xkRu0eMLeRMGCX') %>% 
    select(segments) %>% unnest(segments) %>% 
    select(start, duration, pitches)
highest <- 
    get_tidy_audio_analysis('3eekarcy7kvN4yt5ZFzltW') %>% 
    select(segments) %>% unnest(segments) %>% 
    select(start, duration, pitches)

compmus_long_distance(
    apocalypse %>% mutate(pitches = map(pitches, compmus_normalise, 'chebyshev')),
    highest %>% mutate(pitches = map(pitches, compmus_normalise, 'chebyshev')),
    feature = pitches,
    method = 'euclidean') %>% 
    ggplot(
        aes(
            x = xstart + xduration / 2, 
            width = xduration,
            y = ystart + yduration / 2,
            height = yduration,
            fill = d)) + 
    geom_tile() +
    scale_fill_continuous(type = 'viridis', guide = 'none') +
    labs(x = 'Apocalypse', y = 'The Highest In The Room') +
    theme_minimal()
```

***
There are only two songs that appear in both our playlists. Those songs are Apocalypse by Cigarettes After Sex and Highest In The Room by Travis Scott. These songs are very very different. That's why I have put them together in a chromagram. 

### The Timbre and Chroma in Apocalypse by Cigarettes After Sex and Highest In The Room by Travis Scott.

```{r}

apocalypse_timbre <- get_tidy_audio_analysis('0yc6Gst2xkRu0eMLeRMGCX') %>% 
    compmus_align(bars, segments) %>% 
    select(bars) %>% unnest(bars) %>% 
    mutate(
        pitches = 
            map(segments, 
                compmus_summarise, pitches, 
                method = 'rms', norm = 'euclidean')) %>% 
    mutate(
        timbre = 
            map(segments, 
                compmus_summarise, timbre, 
                method = 'mean'))



apocalypse_timbre %>% 
    compmus_self_similarity(timbre, 'cosine') %>% 
    ggplot(
        aes(
            x = xstart + xduration / 2, 
            width = xduration,
            y = ystart + yduration / 2,
            height = yduration,
            fill = d)) + 
    geom_tile() +
    coord_fixed() +
    scale_fill_viridis_c(option = 'E', guide = 'none') +
    theme_classic() +
    labs(x = '', y = '', title = 'Apocalypse', subtitle = 'Timbre')



highest_timbre <- get_tidy_audio_analysis('3eekarcy7kvN4yt5ZFzltW') %>% 
    compmus_align(beats, segments) %>% 
    select(beats) %>% unnest(beats) %>% 
    mutate(
        pitches = 
            map(segments, 
                compmus_summarise, pitches, 
                method = 'rms', norm = 'euclidean')) %>% 
    mutate(
        timbre = 
            map(segments, 
                compmus_summarise, timbre, 
                method = 'mean'))



highest_timbre %>% 
    compmus_self_similarity(timbre, 'cosine') %>% 
    ggplot(
        aes(
            x = xstart + xduration / 2, 
            width = xduration,
            y = ystart + yduration / 2,
            height = yduration,
            fill = d)) + 
    geom_tile() +
    coord_fixed() +
    scale_fill_viridis_c(option = 'E', guide = 'none') +
    theme_classic() +
    labs(x = '', y = '', title = 'Highest In The Room', subtitle = 'Timbre')


apocalypse_chroma <- get_tidy_audio_analysis('0yc6Gst2xkRu0eMLeRMGCX') %>% 
    compmus_align(bars, segments) %>% 
    select(bars) %>% unnest(bars) %>% 
    mutate(
        pitches = 
            map(segments, 
                compmus_summarise, pitches, 
                method = 'mean', norm = 'manhattan')) %>% 
    mutate(
        chroma = 
            map(segments, 
                compmus_summarise, timbre, 
                method = 'mean'))



apocalypse_chroma %>% 
    compmus_self_similarity(chroma, 'manhattan') %>% 
    ggplot(
        aes(
            x = xstart + xduration / 2, 
            width = xduration,
            y = ystart + yduration / 2,
            height = yduration,
            fill = d)) + 
    geom_tile() +
    coord_fixed() +
    scale_fill_viridis_c(option = 'E', guide = 'none') +
    theme_classic() +
    labs(x = '', y = '', title = 'Apocalypse', subtitle = 'Chroma')


highest_chroma <- get_tidy_audio_analysis('3eekarcy7kvN4yt5ZFzltW') %>% 
    compmus_align(bars, segments) %>% 
    select(bars) %>% unnest(bars) %>% 
    mutate(
        pitches = 
            map(segments, 
                compmus_summarise, pitches, 
                method = 'mean', norm = 'manhattan')) %>% 
    mutate(
        chroma = 
            map(segments, 
                compmus_summarise, timbre, 
                method = 'mean'))



highest_chroma %>% 
    compmus_self_similarity(chroma, 'manhattan') %>% 
    ggplot(
        aes(
            x = xstart + xduration / 2, 
            width = xduration,
            y = ystart + yduration / 2,
            height = yduration,
            fill = d)) + 
    geom_tile() +
    coord_fixed() +
    scale_fill_viridis_c(option = 'E', guide = 'none') +
    theme_classic() +
    labs(x = '', y = '', title = 'Highest In The Room', subtitle = 'Chroma')
```

*** 
There are only two songs that appear in both our playlists: Apocalypse by Cigarettes After Sex and Highest In The Room by Travis Scott. These songs are very different in genre. Apocalypse is slow pop and Highest In The Room is hiphop. So it could be interesting to look at the differences in the self-similarity matrixes. I don't really know how I can make it more workable, so that they are for example, standing next to each other. In all the figures I see a very clear line and a recurring pattern. But I don't see a lot of differences in timbre and chroma. I see almost the same things in timbre and chroma in the figures of Apocalypse. And the same things in timbre and chroma in the figures of Highest In The Room. I do see difference in the patterns of the two songs but I don't know exactly what this difference means... In the visualization of Highest In The Room, there is a clear pattern in the beginning but after two thirds of the song, there is a big change. It becomes instrumental till the end of the song. You can see this in the timbre visualization between 100 and 150. In the song Apocalypse, there is more structure in the pattern but also some differences. In the vocal part, there are some little changes but the instrumental part is more like a river, it continues. I think that you can see that in both the visualizations timbre and chroma. 
